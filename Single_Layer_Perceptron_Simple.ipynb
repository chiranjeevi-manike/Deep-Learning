{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiranjeevi-manike/Deep-Learning/blob/main/Single_Layer_Perceptron_Simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw53m6b1j3d1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "\n",
        "    def __init__(self, learning_rate, epochs):\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    # heaviside activation function\n",
        "\n",
        "    def activation(self, z):\n",
        "      return np.heaviside(z, 0) # haviside(z) heaviside -> activation\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        # Initializing weights and bias\n",
        "        self.weights = np.zeros((n_features))\n",
        "        self.bias = 0\n",
        "\n",
        "        # Iterating until the number of epochs\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Traversing through the entire training set\n",
        "            for i in range(len(X)):\n",
        "                z = np.dot(X, self.weights) + self.bias # Finding the dot product and adding the bias\n",
        "                y_pred = self.activation(z) # Passing through an activation function\n",
        "\n",
        "                #Updating weights and bias\n",
        "                self.weights = self.weights + self.learning_rate * (y[i] - y_pred[i]) * X[i]\n",
        "                self.bias = self.bias + self.learning_rate * (y[i] - y_pred[i])\n",
        "\n",
        "        return self.weights, self.bias\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        return self.activation(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "Yd_eOHuVko8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = iris.data[:, (0, 1)] # petal length, petal width\n",
        "y = (iris.target == 0).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Toq9do90ksoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron = Perceptron(0.001, 100)\n",
        "\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "pred = perceptron.predict(X_test)"
      ],
      "metadata": {
        "id": "sso3DonhlB-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(pred, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpds3Yj4nP-g",
        "outputId": "ea14708b-0e14-4a2e-f349-b308f6308b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(pred, y_test, digits=2)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw7itdQSqdOa",
        "outputId": "05eb6305-8eae-4bbf-b228-971a6f801ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      1.00      0.97        43\n",
            "         1.0       1.00      0.91      0.95        32\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.97      0.95      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "\n",
        "sk_perceptron = Perceptron()\n",
        "sk_perceptron.fit(X_train, y_train)\n",
        "sk_perceptron_pred = sk_perceptron.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "accuracy_score(sk_perceptron_pred, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNFnzsdMqsDP",
        "outputId": "3ac2e7a1-7bbc-4f05-dfb4-fbf0079631f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}